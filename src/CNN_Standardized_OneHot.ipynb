{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efficient-woman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from 64 to 32 bit floats\n",
    "X_test = np.load(\"/home/alon/school/c247a/datasets/project_data/project/X_test.npy\").astype(np.float32)\n",
    "y_test = np.load(\"/home/alon/school/c247a/datasets/project_data/project/y_test.npy\").astype(np.float32)\n",
    "person_train_valid = np.load(\"/home/alon/school/c247a/datasets/project_data/project/person_train_valid.npy\").astype(np.float32)\n",
    "X_train_valid = np.load(\"/home/alon/school/c247a/datasets/project_data/project/X_train_valid.npy\").astype(np.float32)\n",
    "y_train_valid = np.load(\"/home/alon/school/c247a/datasets/project_data/project/y_train_valid.npy\").astype(np.float32)\n",
    "person_test = np.load(\"/home/alon/school/c247a/datasets/project_data/project/person_test.npy\").astype(np.float32)\n",
    "\n",
    "# adjust labels \n",
    "y_train_valid -= 769\n",
    "y_test -= 769\n",
    "\n",
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))\n",
    "print('y_train_valid', y_train_valid[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at a random capture\n",
    "\n",
    "fig, axs = plt.subplots(11,2,figsize=(20,40))\n",
    "\n",
    "count = 0\n",
    "\n",
    "eeg_ix = 10\n",
    "\n",
    "for i in range(22):\n",
    "    axs[int(i/2),count].plot(X_train_valid[eeg_ix,i,:])\n",
    "    axs[int(i/2),count].set_title('EEG Channel {} without noise, no normalization'.format(i))\n",
    "    \n",
    "    count += 1\n",
    "    if (count>1):\n",
    "        count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-praise",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing each channel of a single run\n",
    "\n",
    "fig, axs = plt.subplots(11,2,figsize=(20,40))\n",
    "\n",
    "count = 0\n",
    "\n",
    "eeg_ix = 10\n",
    "\n",
    "for i in range(22):\n",
    "    y = X_train_valid[eeg_ix,i,:]\n",
    "    mean = np.mean(y)\n",
    "    std = np.std(y)\n",
    "    z = (y-mean)/std\n",
    "    \n",
    "    axs[int(i/2),count].plot(z)\n",
    "    axs[int(i/2),count].set_title('EEG Channel {} without noise, standardized'.format(i))\n",
    "    \n",
    "    count += 1\n",
    "    if (count>1):\n",
    "        count=0\n",
    "    #print(np.mean(X_train_valid[eeg_ix,i,:]))\n",
    "    #print(np.std(X_train_valid[eeg_ix,i,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing and then adding noise to every single training input\n",
    "\n",
    "X_train_valid_norm = np.zeros_like(X_train_valid)\n",
    "\n",
    "for eeg_ix in range(X_train_valid.shape[0]):\n",
    "    for i in range(22):\n",
    "        #normalize the data\n",
    "        y = X_train_valid[eeg_ix,i,:]\n",
    "        mean = np.mean(y)\n",
    "        std = np.std(y)\n",
    "        z = (y-mean)/std\n",
    "        X_train_valid_norm[eeg_ix,i,:] = z\n",
    "        \n",
    "mu, sigma = 0, 0.10\n",
    "s = np.random.normal(mu, sigma, X_train_valid_norm.shape)\n",
    "print(\"Noise shape: {}\".format(s.shape))\n",
    "X_train_valid_norm_noised = X_train_valid_norm + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exotic-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing and then adding noise to every single test input\n",
    "\n",
    "X_test_norm = np.zeros_like(X_test)\n",
    "\n",
    "for eeg_ix in range(X_test.shape[0]):\n",
    "    for i in range(22):\n",
    "        #normalize the data\n",
    "        y = X_test[eeg_ix,i,:]\n",
    "        mean = np.mean(y)\n",
    "        std = np.std(y)\n",
    "        z = (y-mean)/std\n",
    "        X_test_norm[eeg_ix,i,:] = z\n",
    "        \n",
    "mu, sigma = 0, 0.10\n",
    "s = np.random.normal(mu, sigma, X_test_norm.shape)\n",
    "print(\"Noise shape: {}\".format(s.shape))\n",
    "X_test_norm_noised = X_test_norm + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statistical-printer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#double check that noise has been added\n",
    "\n",
    "fig, axs = plt.subplots(11,2,figsize=(20,40))\n",
    "\n",
    "count = 0\n",
    "\n",
    "eeg_ix = 10\n",
    "\n",
    "#X_train_valid_norm = np.zeros_like(X_train_valid)\n",
    "\n",
    "for i in range(22):\n",
    "    #normalize the data\n",
    "    #y = X_train_valid[eeg_ix,i,:]\n",
    "    #mean = np.mean(y)\n",
    "    #std = np.std(y)\n",
    "    #z = (y-mean)/std\n",
    "    #X_train_valid_norm[eeg_ix,i,:] = z\n",
    "    \n",
    "    #generate white gaussian noise and add to the data\n",
    "    #mu, sigma = 0, 0.1 # mean and standard deviation\n",
    "    #s = np.random.normal(mu, sigma, 1000)\n",
    "    \n",
    "    #z_noised = z + s\n",
    "    \n",
    "    axs[int(i/2),count].plot(X_train_valid_norm_noised[eeg_ix,i,:])\n",
    "    axs[int(i/2),count].set_title('EEG Channel {} with noise, standardized'.format(i))\n",
    "    \n",
    "    count += 1\n",
    "    if (count>1):\n",
    "        count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(in_arr):\n",
    "    in_arr = in_arr.reshape((in_arr.shape[0],))\n",
    "    in_arr = in_arr.astype(int)\n",
    "    in_arr_1h = np.zeros((in_arr.size, in_arr.max()+1))\n",
    "    in_arr_1h[np.arange(in_arr.size),in_arr] = 1\n",
    "    return in_arr_1h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fancy-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all vectors to one-hot\n",
    "y_train_valid_1h = convert_to_one_hot(y_train_valid)\n",
    "y_test_1h = convert_to_one_hot(y_test)\n",
    "\n",
    "person_train_valid_1h = convert_to_one_hot(person_train_valid)\n",
    "person_test_1h = convert_to_one_hot(person_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-commerce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate and initialize pandas dataframes\n",
    "\n",
    "columns = ['subject_ix', 'subject_one_hot', 'data_22ch', 'event_class_ix', 'event_class_one_hot']\n",
    "\n",
    "train_val_df = pd.DataFrame(columns=columns)\n",
    "train_val_df['subject_ix'] = person_train_valid.reshape((person_train_valid.shape[0],))\n",
    "train_val_df['subject_one_hot'] = person_train_valid_1h.tolist()\n",
    "train_val_df['event_class_ix'] = y_train_valid\n",
    "train_val_df['event_class_one_hot'] = y_train_valid_1h.tolist()\n",
    "#train_val_df['data_22ch'] = X_train_valid.tolist()\n",
    "train_val_df['data_22ch_std'] = X_train_valid_norm.tolist()\n",
    "#train_val_df['data_22ch_std_noise'] = X_train_valid_norm_noised.tolist()\n",
    "\n",
    "test_df = pd.DataFrame(columns=columns)\n",
    "test_df['subject_ix'] = person_test.reshape((person_test.shape[0],))\n",
    "test_df['subject_one_hot'] = person_test_1h.tolist()\n",
    "test_df['event_class_ix'] = y_test\n",
    "test_df['event_class_one_hot'] = y_test.tolist()\n",
    "#test_df['data_22ch'] = X_test.tolist()\n",
    "test_df['data_22ch_std'] = X_test_norm.tolist()\n",
    "#test_df['data_22ch_std_noise'] = X_test_norm_noised.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#examples of obtaining train_val and test dataframes from the larger dataframes\n",
    "\n",
    "s0_train_val_df = train_val_df[train_val_df['subject_ix'] == 0]\n",
    "s0_test_df = test_df[test_df['subject_ix'] == 0]\n",
    "\n",
    "s1_train_val_df = train_val_df[train_val_df['subject_ix'] == 1]\n",
    "s1_test_df = test_df[test_df['subject_ix'] == 1]\n",
    "\n",
    "s2_train_val_df = train_val_df[train_val_df['subject_ix'] == 2]\n",
    "s2_test_df = test_df[test_df['subject_ix'] == 2]\n",
    "\n",
    "s3_train_val_df = train_val_df[train_val_df['subject_ix'] == 3]\n",
    "s3_test_df = test_df[test_df['subject_ix'] == 3]\n",
    "\n",
    "s4_train_val_df = train_val_df[train_val_df['subject_ix'] == 4]\n",
    "s4_test_df = test_df[test_df['subject_ix'] == 4]\n",
    "\n",
    "s5_train_val_df = train_val_df[train_val_df['subject_ix'] == 5]\n",
    "s5_test_df = test_df[test_df['subject_ix'] == 5]\n",
    "\n",
    "s6_train_val_df = train_val_df[train_val_df['subject_ix'] == 6]\n",
    "s6_test_df = test_df[test_df['subject_ix'] == 6]\n",
    "\n",
    "s7_train_val_df = train_val_df[train_val_df['subject_ix'] == 7]\n",
    "s7_test_df = test_df[test_df['subject_ix'] == 7]\n",
    "\n",
    "s8_train_val_df = train_val_df[train_val_df['subject_ix'] == 8]\n",
    "s8_test_df = test_df[test_df['subject_ix'] == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coral-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#example of grabbing the data from a given subject df\n",
    "s0_X_train_val = np.array([[[value for value in ch] for ch in run] for run in s0_train_val_df['data_22ch'].values], ndmin=3)\n",
    "#s0_X_train_val = np.array(s0_train_val_df['data_22ch'].values)\n",
    "s0_y_train_val = s0_train_val_df['subject_ix'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_train_val(df):\n",
    "    return np.array([[[value for value in ch] for ch in run] for run in df['data_22ch'].values], ndmin=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_X_train_val = get_X_train_val(s2_train_val_df)\n",
    "print(s2_X_train_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ksquare(x):\n",
    "  return tf.pow(x, 2)\n",
    "\n",
    "def klog(x):\n",
    "  return tf.math.log(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer is used to instantiate a tensor\n",
    "# Dimensions are (E,T) -> (22, 1000)\n",
    "input_ = layers.Input(shape=(22, 1000))\n",
    "\n",
    "# Reshape layer reshapes input into given shape\n",
    "# output shape is (batch_size,) + target_shape\n",
    "r1 = layers.Reshape(target_shape=(22, 1000, 1))(input_)\n",
    "\n",
    "# Temporal convolution layer\n",
    "# kernel_size is (H,W)\n",
    "# for channels_last input is a 4D-tensor with dims batch_size + (rows, cols, )\n",
    "c1 = layers.Conv2D(filters=40, kernel_size=(1,50), data_format='channels_last',\n",
    "                   activation='elu')(r1)\n",
    "\n",
    "# Permute layer\n",
    "p1 = layers.Permute(dims=(2,1,3))(c1)\n",
    "\n",
    "# Reshape layer\n",
    "#r2 = layers.Reshape((976, 22*40))(p1)\n",
    "r2 = layers.Reshape((951, 22*40))(p1)\n",
    "\n",
    "#Dropout\n",
    "#dr1 = layers.Dropout(0.8)(r2)\n",
    "\n",
    "# FC layer\n",
    "d1 = layers.Dense(40, activation='elu')(r2)\n",
    "#d1 = layers.Dense(40, activation='elu')(dr1)\n",
    "\n",
    "#Dropout\n",
    "dr1 = layers.Dropout(0.8)(d1)\n",
    "\n",
    "\n",
    "# Activation layer using ksquare\n",
    "#sq1 = layers.Activation(ksquare)(d1)\n",
    "sq1 = layers.Activation(ksquare)(dr1)\n",
    "\n",
    "# Mean pooling layer\n",
    "ap1 = layers.AveragePooling1D(75, strides=15)(sq1)\n",
    "\n",
    "# Log activation layer\n",
    "log1 = layers.Activation(klog)(ap1)\n",
    "\n",
    "# Flatten layer\n",
    "f1 = layers.Flatten()(log1)\n",
    "\n",
    "# Output layer\n",
    "output_ = layers.Dense(4, activation='softmax')(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Model(inputs=input_, outputs=output_, name='shallow_convnet')\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-aberdeen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_val = get_X_train_val(s2_train_val_df)\n",
    "# print(s2_X_train_val.shape)\n",
    "#train_val_df['event_class_one_hot'].values\n",
    "print(y_train_valid_1h.shape)\n",
    "print(type(y_train_valid_1h))\n",
    "print(y_train_valid_1h[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepting-diversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist = model.fit(X_train_valid_norm, y_train_valid_1h, \n",
    "                      validation_split=0.2, epochs=50,\n",
    "                      verbose=True)\n",
    "\n",
    "hist = loss_hist.history\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(hist['loss'])\n",
    "plt.plot(hist['val_loss'])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(hist['acc'])\n",
    "plt.plot(hist['val_acc'])\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-treaty",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-yorkshire",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wicked-remedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing each channel of each run and adding noise\n",
    "\n",
    "fig, axs = plt.subplots(11,2,figsize=(20,40))\n",
    "\n",
    "count = 0\n",
    "\n",
    "eeg_ix = 10\n",
    "\n",
    "#X_train_valid_norm = np.zeros_like(X_train_valid)\n",
    "\n",
    "for i in range(22):\n",
    "    #normalize the data\n",
    "    y = X_train_valid[eeg_ix,i,:]\n",
    "    mean = np.mean(y)\n",
    "    std = np.std(y)\n",
    "    z = (y-mean)/std\n",
    "    #X_train_valid_norm[eeg_ix,i,:] = z\n",
    "    \n",
    "    #generate white gaussian noise and add to the data\n",
    "    #mu, sigma = 0, 0.1 # mean and standard deviation\n",
    "    #s = np.random.normal(mu, sigma, 1000)\n",
    "    \n",
    "    #z_noised = z + s\n",
    "    \n",
    "    axs[int(i/2),count].plot(z_noised)\n",
    "    axs[int(i/2),count].set_title('EEG Channel {} with noise, standardized'.format(i))\n",
    "    \n",
    "    count += 1\n",
    "    if (count>1):\n",
    "        count=0\n",
    "\n",
    "        \n",
    "mu, sigma = 0, 0.1\n",
    "s = np.random.normal(mu, sigma, X_train_valid_norm.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing each channel of each run and adding noise\n",
    "\n",
    "# fig, axs = plt.subplots(11,2,figsize=(20,40))\n",
    "\n",
    "# count = 0\n",
    "\n",
    "# eeg_ix = 10\n",
    "\n",
    "X_train_valid_norm = np.zeros_like(X_train_valid)\n",
    "\n",
    "for eeg_ix in range(X_train_valid.shape[0]):\n",
    "    for i in range(22):\n",
    "        #normalize the data\n",
    "        y = X_train_valid[eeg_ix,i,:]\n",
    "        mean = np.mean(y)\n",
    "        std = np.std(y)\n",
    "        z = (y-mean)/std\n",
    "        X_train_valid_norm[eeg_ix,i,:] = z\n",
    "    \n",
    "    #generate white gaussian noise and add to the data\n",
    "    #mu, sigma = 0, 0.1 # mean and standard deviation\n",
    "    #s = np.random.normal(mu, sigma, 1000)\n",
    "    \n",
    "    #z_noised = z + s\n",
    "    \n",
    "    #axs[int(i/2),count].plot(z_noised)\n",
    "    #axs[int(i/2),count].set_title('EEG Channel {} with noise, standardized'.format(i))\n",
    "    \n",
    "    #count += 1\n",
    "    #if (count>1):\n",
    "    #    count=0\n",
    "\n",
    "        \n",
    "mu, sigma = 0, 0.10\n",
    "s = np.random.normal(mu, sigma, X_train_valid_norm.shape)\n",
    "print(\"Noise shape: {}\".format(s.shape))\n",
    "X_train_valid_norm_noised = X_train_valid_norm + s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(11,2,figsize=(20,40))\n",
    "\n",
    "count = 0\n",
    "\n",
    "eeg_ix = 10\n",
    "\n",
    "#X_train_valid_norm = np.zeros_like(X_train_valid)\n",
    "\n",
    "for i in range(22):\n",
    "    #normalize the data\n",
    "    #y = X_train_valid[eeg_ix,i,:]\n",
    "    #mean = np.mean(y)\n",
    "    #std = np.std(y)\n",
    "    #z = (y-mean)/std\n",
    "    #X_train_valid_norm[eeg_ix,i,:] = z\n",
    "    \n",
    "    #generate white gaussian noise and add to the data\n",
    "    #mu, sigma = 0, 0.1 # mean and standard deviation\n",
    "    #s = np.random.normal(mu, sigma, 1000)\n",
    "    \n",
    "    #z_noised = z + s\n",
    "    \n",
    "    axs[int(i/2),count].plot(X_train_valid_norm_noised[eeg_ix,i,:])\n",
    "    axs[int(i/2),count].set_title('EEG Channel {} with noise, standardized'.format(i))\n",
    "    \n",
    "    count += 1\n",
    "    if (count>1):\n",
    "        count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-blind",
   "metadata": {},
   "outputs": [],
   "source": [
    "#our model is overfitting - there aren't enough examples\n",
    "#now let's try adding noise to the data in order to generate more examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-jacob",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-heating",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bigger-hobby",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "steady-league",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try to do a split in time to get every other sample, so instead of 236x22x1000 we have 472x22x500 or even every 4 samples\n",
    "ixs_even = np.arange(0, s2_X_train_val.shape[0] + 1, 2)\n",
    "ixs_odd = np.arange(1, s2_X_train_val.shape[0] + 1, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
