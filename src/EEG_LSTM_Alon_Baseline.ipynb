{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.models as models\n",
    "import tensorflow.keras.layers as layers\n",
    "\n",
    "import pandas as pd\n",
    "from pandas import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-number",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from 64 to 32 bit floats\n",
    "X_test = np.load(\"/home/alon/school/c247a/datasets/project_data/project/X_test.npy\").astype(np.float32)\n",
    "y_test = np.load(\"/home/alon/school/c247a/datasets/project_data/project/y_test.npy\").astype(np.float32)\n",
    "person_train_valid = np.load(\"/home/alon/school/c247a/datasets/project_data/project/person_train_valid.npy\").astype(np.float32)\n",
    "X_train_valid = np.load(\"/home/alon/school/c247a/datasets/project_data/project/X_train_valid.npy\").astype(np.float32)\n",
    "y_train_valid = np.load(\"/home/alon/school/c247a/datasets/project_data/project/y_train_valid.npy\").astype(np.float32)\n",
    "person_test = np.load(\"/home/alon/school/c247a/datasets/project_data/project/person_test.npy\").astype(np.float32)\n",
    "\n",
    "# adjust labels \n",
    "y_train_valid -= 769\n",
    "y_test -= 769\n",
    "\n",
    "print ('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print ('Test data shape: {}'.format(X_test.shape))\n",
    "print ('Training/Valid target shape: {}'.format(y_train_valid.shape))\n",
    "print ('Test target shape: {}'.format(y_test.shape))\n",
    "print ('Person train/valid shape: {}'.format(person_train_valid.shape))\n",
    "print ('Person test shape: {}'.format(person_test.shape))\n",
    "print('y_train_valid', y_train_valid[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expired-obligation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert y_train_valid to one-hot\n",
    "y_train_valid = y_train_valid.astype(int)\n",
    "y_train_valid_one_hot = np.zeros((y_train_valid.size, y_train_valid.max()+1))\n",
    "y_train_valid_one_hot[np.arange(y_train_valid.size),y_train_valid] = 1\n",
    "print(y_train_valid_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-village",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps = X_train_valid.shape[2]\n",
    "n_features = X_train_valid.shape[1]\n",
    "n_outputs = y_train_valid_one_hot.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-wisconsin",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(['seaborn-muted', 'seaborn-talk'])\n",
    "plt.rcParams['figure.figsize'] = (16,9)\n",
    "\n",
    "num_channels = 3\n",
    "num_trials = 3\n",
    "fig, ax = plt.subplots(num_channels, num_trials, sharex='col', sharey='row')\n",
    "for i in range(num_trials):\n",
    "  for j in range(num_channels):\n",
    "    ax[j,i].plot(X_train_valid[i*700,j*7,:].T)\n",
    "    if j == len(ax) - 1:\n",
    "      ax[j,i].set_xlabel(f'Trial {i*700}, '\n",
    "                         f'Subject {int(person_train_valid[i*700,0])}, '\n",
    "                         f'Label {y_train_valid[i*700]}')\n",
    "    if i == 0:\n",
    "      ax[j,i].set_ylabel(f'Electrode {j*7}')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.LSTM(128, input_shape=(n_features,n_timesteps)))\n",
    "model.add(layers.Dropout(0.9))\n",
    "model.add(layers.Dense(500, activation='relu'))\n",
    "model.add(layers.Dense(100, activation='relu'))\n",
    "model.add(layers.Dense(n_outputs, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-separate",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential() #initialize sequential model\n",
    "model.add(layers.LSTM(1024, input_shape=(n_features,n_timesteps), return_sequences=True)) #LSTM layer with 32 neurons\n",
    "model.add(layers.LSTM(256, return_sequences=True)) #LSTM layer with 32 neurons\n",
    "model.add(layers.LSTM(256)) #LSTM layer with 32 neurons\n",
    "model.add(layers.Dropout(0.9))\n",
    "model.add(layers.Dense(500,activation='relu')) #Dense layer with 16 neurons\n",
    "model.add(layers.Dense(100,activation='relu')) #Dense layer with 8 neurons\n",
    "model.add(layers.Dense(n_outputs, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-missile",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ksquare(x):\n",
    "    return tf.pow(x, 2)\n",
    "\n",
    "def klog(x):\n",
    "    return tf.math.log(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-carbon",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(22, 64, 3, batch_first=True, dropout=DROPOUT)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(64, 54),\n",
    "            nn.BatchNorm1d(num_features=54, eps=1e-05, momentum=0.2, affine=True),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Dropout(p=DROPOUT),\n",
    "            nn.Linear(54, 44),\n",
    "            nn.BatchNorm1d(num_features=44, eps=1e-05, momentum=0.2, affine=True),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Linear(44, 4)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, h=None):\n",
    "\n",
    "        # LSTM\n",
    "        N, C, H, W = x.size()\n",
    "        x = x.view(N, H, W).permute(0, 2, 1)\n",
    "        out, _ = self.lstm(x)\n",
    "\n",
    "        # Fully Connected Layer\n",
    "        out = self.fc(out[:, -1, :])\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential() #initialize sequential model\n",
    "#model.add(layers.Reshape(input_shape=(n_features,n_timesteps), target_shape=(22, 1000, 1)))\n",
    "model.add(layers.Conv1D(input_shape=(n_features,n_timesteps), filters=40, kernel_size=, data_format='channels_last',\n",
    "                   activation='elu'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-salon",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_hist = model.fit(X_train_valid, y_train_valid_one_hot, \n",
    "                      validation_split=0.2, epochs=100,\n",
    "                      verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
    "# list all data in history\n",
    "print(loss_hist.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(loss_hist.history['accuracy'])\n",
    "plt.plot(loss_hist.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(loss_hist.history['loss'])\n",
    "plt.plot(loss_hist.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-finish",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-theorem",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerical-grocery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
