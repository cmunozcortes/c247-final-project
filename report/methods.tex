\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{float}

\author{Alon Krauthammer, Mark Kubiak, Chris Munoz, Eashan Samak}
\title{\vspace{-2cm}ECE C247 Final Project\\
Methods}

\begin{document}
\maketitle

\section{Detailed Results}
Table \ref{tab:acc} shows the validation accuracy and the test accuracy for each
model we evaluated. In addition to the task of classification across all
subjects, we trained our shallow CNN for the task of subject-specific
classification. Table \ref{tab:subj} shows the accuracy performance for
subject-dependent classification.

% Table with accuracy results across all subjects
\begin{table}[H]
\small
\begin{center}
    \begin{tabular}{|l|c|c|}
        \hline
        Model           & Validation Accuracy & Test Accuracy   \\
        \hline\hline
        Shallow CNN     & 0.768               & 0.731           \\
        SCNN            & 0.704               & 0.654           \\
        SCNN+LSTM       & 0.758               & 0.765           \\
        \hline
    \end{tabular}
\end{center}
\caption{Best accuracy results over all subjects in BCI IV dataset 2a.}
\label{tab:acc}
\end{table}

% Table with accuracy results per subject (Shallow CNN)
\begin{table}[H]
\small
\begin{center}
    \begin{tabular}{|c|c|c|}
        \hline
        Subject & Validation Accuracy   & Test Accuracy \\
        \hline\hline
        1       & 0.822  & 0.700    \\
        2       & 0.600  & 0.560    \\
        3       & 0.898  & 0.840    \\
        4       & 0.681  & 0.700    \\
        5       & 0.721  & 0.766    \\
        6       & 0.581  & 0.510    \\
        7       & 0.848  & 0.740    \\
        8       & 0.878  & 0.760    \\
        9       & 0.829  & 0.872    \\
        \hline
    \end{tabular}
\end{center}
\caption{Best accuracy results for each subject with Shallow CNN model.}
\label{tab:subj}
\end{table}

%\subsection{Loss and Accuracy Plots}
%Figure \ref{fig:lstm} shows the accuracy and loss over training epochs for the
%SCNN+LSTM model. The plot shows how the model begins to overfit the training
%data starting around epoch 75. Multiple attempts were made to tune the dropout
%parameter to try to reduce overfitting; however, over the limited number of
%attemps less overfitting resulted in lower test accuracy.
%\begin{figure}[H]
%    \centering
%    \includegraphics[scale=0.35]{img/scnn.png}
%    \caption{Loss and accuracy plots for SCNN}
%    \label{fig:lstm}
%\end{figure}
%\begin{figure}[H]
%    \centering
%    \includegraphics[scale=0.35]{img/rascnn.png}
%    \caption{Loss and accuracy plots for SCNN+LSTM model}
%    \label{fig:lstm}
%\end{figure}

\section{Model Architectures}
\begin{table}[H]
\small
\begin{center}
    \begin{tabular}{|l|l|l|}
        \hline
        Layer   & Output shape  & Num. of parameters \\
        \hline\hline
        Reshape             & $(N, 22, 500, 1)$     & 0     \\
        Conv2D              & $(N, 22, 476, 40)$    & 1040  \\
        Permute             & $(N, 476, 22, 40)$    & 0     \\
        Reshape             & $(N, 476, 880)$       & 0     \\
        Dense               & $(N, 476, 40)$        & 0     \\
        Activation          & $(N, 476, 40)$        & 35240 \\
        Average pooling 1D  & $(N, 27, 40)$         & 0     \\
        Activation          & $(N, 27, 40)$         & 0     \\
        Flatten             & $(N, 1080)$           & 0     \\
        Dropout             & $(N, 1080)$           & 0     \\
        Dense               & $(N, 4)$              & 4324  \\
        \hline
    \end{tabular}
\end{center}
\caption{Architecture summary for shallow CNN model.}
\label{tab:shallow}
\end{table}

\begin{table}[H]
\small
\begin{center}
    \begin{tabular}{|l|l|l|}
        \hline
        Layer   & Output shape  & Num. of parameters \\
        \hline\hline
        Input layer         & $(N, 1000, 22)$       & 0         \\
        Reshape             & $(N, 1000, 22, 1)$    & 0         \\
        Conv2D              & $(N, 1000, 12, 100)$  & 1100      \\
        Conv2D              & $(N, 1000, 1, 100)$   & 120000    \\
        Batch norm          & $(N, 1000, 1, 100)$   & 400       \\
        Spatial dropout 2D  & $(N, 1000, 1, 100)$   & 0         \\
        Conv2D              & $(N, 977, 1, 40)$     & 96000     \\
        Conv2D              & $(N, 954, 1,40)$      & 38400     \\
        Conv2D              & $(N, 931, 1, 40)$     & 38400     \\
        Conv2D              & $(N, 908, 1, 40)$     & 38400     \\
        Batch norm          & $(N, 908, 1, 40)$     & 160       \\
        Average pooling 2D  & $(N, 45, 1, 40)$      & 0         \\
        Spatial dropout 2D  & $(N, 45, 1, 40)$      & 0         \\
        Flatten             & $(N, 1800)$           & 0         \\
        Dense               & $(N, 4)$              & 7204      \\
        \hline
    \end{tabular}
\end{center}
\caption{Architecture summary for SCNN model.}
\label{tab:scnn}
\end{table}

\begin{table}[H]
\small
\begin{center}
    \begin{tabular}{|l|l|l|}
        \hline
        Layer   & Output shape  & Num. of parameters \\
        \hline\hline
        Input layer         & $(N, 1000, 22)$       & 0         \\
        Reshape             & $(N, 1000, 22, 1)$    & 0         \\
        Conv2D              & $(N, 1000, 12, 100)$  & 1100      \\
        Conv2D              & $(N, 1000, 1, 100)$   & 120000    \\
        Batch norm          & $(N, 1000, 1, 100)$   & 400       \\
        Spatial dropout 2D  & $(N, 1000, 1, 100)$   & 0         \\
        Conv2D              & $(N, 977, 1, 40)$     & 96000     \\
        Conv2D              & $(N, 954, 1,40)$      & 38400     \\
        Conv2D              & $(N, 931, 1, 40)$     & 38400     \\
        Conv2D              & $(N, 908, 1, 40)$     & 38400     \\
        Batch norm          & $(N, 908, 1, 40)$     & 160       \\
        Average pooling 2D  & $(N, 45, 1, 40)$      & 0         \\
        Spatial dropout 2D  & $(N, 45, 1, 40)$      & 0         \\
        Reshape             & $(N, 45, 40)$         & 0         \\
        Birectional LSTM    & $(N, 45, 152)$        & 95080     \\
        Flatten             & $(N, 6840)$           & 0         \\
        Dense               & $(N, 4)$              & 27364     \\
        \hline
    \end{tabular}
\end{center}
\caption{Architecture summary for SCNN+LSTM model.}
\label{tab:lstm}
\end{table}

%\pagebreak
%\section{Additional Notes}
%We performed a series of explorations on the dataset itself, seeking to quantify
%any degree of class imbalance, model performance on a per-subject basis, and
%model performance on the task of subject classification instead of action
%classification. It was found that, while the training set was well-balanced,
%the validation and test sets were actually imbalanced: the validation set
%contained the largest number of its examples for the ‘Both Feet’ class, whereas
%the test set contained the fewest number of its examples in this same class. We
%believe that this class imbalance could have caused the dropoff in performance
%between validation and test sets for the model described above.
%
%\begin{figure}[H]
%    \centering
%    \includegraphics[scale=0.33]{img/imbalance.png}
%    \caption{Class imbalance in validation and test sets.}
%    \label{fig:imb}
%\end{figure}


\end{document}
