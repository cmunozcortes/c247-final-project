\documentclass[10pt,twocolumn,letterpaper]{article}

\usepackage{cvpr}
\usepackage{times}
\usepackage{epsfig}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[inline]{enumitem}

% Include other packages here, before hyperref.

% If you comment hyperref and then uncomment it, you should delete
% egpaper.aux before re-running latex.  (Or just hit 'q' on the first latex
% run, let it finish, and you should be clear).
\usepackage[breaklinks=true,bookmarks=false]{hyperref}

\cvprfinalcopy % *** Uncomment this line for the final submission

\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\httilde{\mbox{\tt\raisebox{-.5ex}{\symbol{126}}}}

% Pages are numbered in submission mode, and unnumbered in camera-ready
%\ifcvprfinal\pagestyle{empty}\fi
%\setcounter{page}{4321}
\begin{document}

%%%%%%%%% TITLE
\title{
    EEG Classification for Motor Imagery Tasks\\
    {\large ECE C247 Final Project}
}

\author{Alon Krauthammer\\
{\tt\small alonk@ucla.edu}
\and
Mark Kubiak\\
{\tt\small markkubiak@ucla.edu}
\and
Chris Munoz\\
{\tt\small cmunozcortes@ucla.edu}
\and
Eashan Samak\\
{\tt\small esamak@ucla.edu}
}

\maketitle
%\thispagestyle{empty}

%%%%%%%%% ABSTRACT
\begin{abstract}
   The ABSTRACT is to be in fully-justified italicized text, at the top
   of the left-hand column, below the author and affiliation
   information. Use the word ``Abstract'' as the title, in 12-point
   Times, boldface type, centered relative to the column, initially
   capitalized. The abstract is to be in 10-point, single-spaced type.
   Leave two blank lines after the Abstract, then begin the main text.
   Look at previous CVPR abstracts to get a feel for style and length.
\end{abstract}

%%%%%%%%% BODY TEXT
\section{Introduction}
Brain-computer interfaces (BCIs) provide a direct path of communication to
measure and record brain activity. BCIs can infer human intent from these
neural activity measurements and allow individuals who have lost motor
functions gain control external devices without movement. %TODO: add citation
% brain-computer interfaces: a gentle introduction by graimann & allison 
This technique is known as motor imagery (MI).

Most BCI methods record electrical signals using electrodes
placed on the surface of the scalp (electroencephalography, EEG), or on the
surface of the cerebral cortex. EEG-based motor imagery (EEG MI) is one of the
most popular techniques in BCI due to its non-invasiness, high temporal
resolution, and portability. %TODO: add citation - brain-machine interfaces
% from motor to mood - shanechi mm.

Decoding of raw EEG signals for motor imagery tasks can be realized through a
variety of methods. These methods can be classify into five main categories:
\begin{enumerate*}
    \item linear classifiers (e.g. support vector machine, SVM),
    \item nonlinear Bayesian classifiers (e.g. hidden Markov models HMM),
    \item nearest neighbor classifiers (e.g. $k$-nearest neighbors, KNN),
    \item neural networks, (e.g. multi-layer perception, MLP), and
    \item combinaton of different methods using boosting or voting
\end{enumerate*} % TODO: add citation - LSTM-based eeg classification... p.wang

Generally, these methods require pre-processing of the data to overcome low
signal-to-noise ratios (SNR) typical of these recordings. %TODO: add citation -
%ML for MEG during speech tasks, kostas et al.
A variety of pre-processing techniques exist to extract useful features from the
data. Popular techniques include cropping, trial averaging, normalization,
band-pass filtering, and spatial transforms such as common spatial patterns
(CSP). One shortcoming of this approach is that the expert knowledge these
techniques require can introduce bias and may reinforce underlying assumptions
about the data. %TODO: add citation - kostas et al again.
In contrast, neural networks have the ability to learn representations of the
raw data without any pre-processing steps and can consider potentially unknown
correlations in the data. %TODO: kostas et al.



% Add the idea below to the conclusions
%In practice, however, this is difficult to achieve. The reason is that
%extracting features to express raw EEG signals in a form suitable for a neural
%network is not a trivial task. 

\section{Results}

All manuscripts must be in English.

\subsection{Data Augmentation}

\subsubsection{\Mu and \Beta Band Filtering}

% Chris 03/06: I found a paper where they use a 5th order butterworth filter to
% extract the mu band (8-13Hz) and the beta band (13-30Hz), which correspond to
% ERD and ERS (Event-related desynchronization and event-related
% synchronization) [don't ask me what those mean]. The paper trains a model with
% our data. Just throwing this out there.
% Mark: Is this it??
% https://hal.archives-ouvertes.fr/file/index/docid/837516/filename/Template.pdf

BCI research has shown that Event-Related Synchronization (ERS) and
Event-Related Desynchronization (ERD) are highly correlated with motion and have
high activity in the $\Mu$ band (8Hz to 13Hz) and $\Beta$ band (13Hz to 30Hz).
% TODO quote the right paper (I think the one above)
Convolutional filter sizes at the first layer were chosen to capture features of
these frequencies, but a data augmentation strategy to present the $\Mu$ and
$\Beta$ bands was attempted. This strategy copied the 22 EEG channels, one set
with a 6th-order Butterworth filter around the $\Mu$ frequency and another set
with a 6th-order Butterworth filter around the $\Beta$ frequency. The unfiltered
set and two filtered sets were concatenated to generate a $(66 \times 1000)$
sized sample. This was tried against three separate architectures - a deep CNN,
shallow CNN, and CNN+LSTM. All three models experienced either the same
performance with this augmentation or a degradation in performance. This
indicates that either these frequencies were unimportant or the model was
able to learn filters to distinguish features in these frequencies. Future work
may want to change the extra features to a measurement of power in these bands
with time.

% Another failed attempt at data augmentation was generating extra examples with
% Additive White Gaussian Noise (AWGN.) This was intended to help mitigate the
% sever overfitting issues of early deep convolutional networks. The number of
% examples was increased by a factor of 10,

\section{Discussion}

Please refer to the author guidelines on the CVPR 2015 web page for a
discussion of the policy on dual submissions.

\begin{figure}[t]
\begin{center}
\fbox{\rule{0pt}{2in} \rule{0.9\linewidth}{0pt}}
   %\includegraphics[width=0.8\linewidth]{egfigure.eps}
\end{center}
   \caption{Example of caption.  It is set in Roman so that mathematics
   (always set in Roman: $B \sin A = A \sin B$) may be included without an
   ugly clash.}
\label{fig:long}
\label{fig:onecol}
\end{figure}

\section{References}

\noindent
Compare the following:\\
\begin{tabular}{ll}
 \verb'$conf_a$' &  $conf_a$ \\
 \verb'$\mathit{conf}_a$' & $\mathit{conf}_a$
\end{tabular}\\
See The \TeX book, p165.

The space after \eg, meaning ``for example'', should not be a
sentence-ending space. So \eg is correct, {\em e.g.} is not.  The provided
\verb'\eg' macro takes care of this.

When citing a multi-author paper, you may save space by using ``et alia'',
shortened to ``\etal'' (not ``{\em et.\ al.}'' as ``{\em et}'' is a complete word.)
However, use it only when there are three or more authors.  Thus, the
following is correct: ``
   Frobnication has been trendy lately.
   It was introduced by Alpher~\cite{Alpher02}, and subsequently developed by
   Alpher and Fotheringham-Smythe~\cite{Alpher03}, and Alpher \etal~\cite{Alpher04}.''

This is incorrect: ``... subsequently developed by Alpher \etal~\cite{Alpher03} ...''
because reference~\cite{Alpher03} has just two authors.  If you use the
\verb'\etal' macro provided, then you need not worry about double periods
when used at the end of a sentence as in Alpher \etal.

For this citation style, keep multiple citations in numerical (not
chronological) order, so prefer \cite{Alpher03,Alpher02,Authors14} to
\cite{Alpher02,Alpher03,Authors14}.


\begin{figure*}
\begin{center}
\fbox{\rule{0pt}{2in} \rule{.9\linewidth}{0pt}}
\end{center}
   \caption{Example of a short caption, which should be centered.}
\label{fig:short}
\end{figure*}

\subsection{Footnotes}

Please use footnotes\footnote {This is what a footnote looks like.  It
often distracts the reader from the main flow of the argument.} sparingly.
Indeed, try to avoid footnotes altogether and include necessary peripheral
observations in
the text (within parentheses, if you prefer, as in this sentence).  If you
wish to use a footnote, place it at the bottom of the column on the page on
which it is referenced. Use Times 8-point type, single-spaced.


%-------------------------------------------------------------------------
\section{References}

List and number all bibliographical references in 9-point Times,
single-spaced, at the end of your paper. When referenced in the text,
enclose the citation number in square brackets, for
example~\cite{Authors14}.  Where appropriate, include the name(s) of
editors of referenced books.

\begin{table}
\begin{center}
\begin{tabular}{|l|c|}
\hline
Method & Frobnability \\
\hline\hline
Theirs & Frumpy \\
Yours & Frobbly \\
Ours & Makes one's heart Frob\\
\hline
\end{tabular}
\end{center}
\caption{Results.   Ours is better.}
\end{table}

When placing figures in \LaTeX, it's almost always best to use
\verb+\includegraphics+, and to specify the  figure width as a multiple of
the line width as in the example below
{\small\begin{verbatim}
   \usepackage[dvips]{graphicx} ...
   \includegraphics[width=0.8\linewidth]
                   {myfile.eps}
\end{verbatim}
}

{\small
\bibliographystyle{ieee}
\bibliography{egbib}
}

\end{document}
